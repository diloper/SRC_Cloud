{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diloper/SRC_Cloud/blob/colab/random_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "dir='./small_test/'\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/RD_程式開發/SRC_deploy') \n",
        "os.listdir() #確認目錄內容"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x52lDjKI9MoO",
        "outputId": "5ba03f88-663e-439e-90ee-fb13d4c87149"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t104.7z',\n",
              " 't100.7z',\n",
              " 'B.csv',\n",
              " 'small_test',\n",
              " 'SQLite_Sample.7z',\n",
              " 'SRC_deploy2344.sqlite',\n",
              " 'small_test2344.sqlite']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RIoTTiIUKU5F"
      },
      "outputs": [],
      "source": [
        "# %load random_test.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# %load random_test.py\n",
        "\n",
        "import re , os , sqlite3\n",
        "import pandas as pd\n",
        "# import read_file_analyze as ka\n",
        "from datetime import date, timedelta, datetime\n",
        "\n",
        "def regexp(expr, item):\n",
        "    reg = re.compile(expr)\n",
        "    return reg.search(item) is not None\n",
        "\n",
        "def find_SRC_negative_v2(dir,stockid,boundary=300):\n",
        "#     now = datetime.now()\n",
        "#     Today = now.strftime(\"%Y-%m-%d\")\n",
        "#     print(Today)\n",
        "#     current_date = (now-timedelta(days=120)).isoformat()\n",
        "    price_db_name=dir+str(stockid)+\".sqlite\"\n",
        "    if os.path.isfile(price_db_name) is not True:\n",
        "        return\n",
        "    price_db_handler = sqlite3.connect(price_db_name)\n",
        "    df = pd.read_sql_query('SELECT * from (SELECT OHLC.Date,OHLC.Close, SRC.M20 from SRC INNER JOIN OHLC ON SRC.Date = OHLC.Date order by SRC.Date desc LIMIT \"'+str(boundary)+'\") order by date ASC',price_db_handler)\n",
        "    df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    price_db_handler.close()\n",
        "\n",
        "    df['SRC M20 5dt']=(df['M20']-df['M20'].shift(5))/5\n",
        "#   抓取SRC 5dt連續性\n",
        "    df['SRC 5dt_G_R']=df['SRC M20 5dt']/abs(df['SRC M20 5dt'])\n",
        "    df['5dt_G_R_sum']=df['SRC 5dt_G_R'].rolling(window=10,min_periods=10).sum()\n",
        "#     df.loc[df['M20'] <0&, 'name_match'] = 'Match'\n",
        "    date_before = date.today() - timedelta(days=boundary)\n",
        "#     print(date_before)\n",
        "#    df.loc[(df['M20']<0) & (df['M20']>=-0.1)& (df['5dt_G_R_sum']>8) & (df['Date'] > str(date_before)),'RRR']=1\n",
        "# 可調整 SRC 條件\n",
        "    A=df.loc[(df['M20']<0) & (df['M20']>=-0.1)& (df['5dt_G_R_sum']>8) & (df['Date'] > str(date_before)) ]\n",
        "#    A=df.loc[df['RRR']==1]\n",
        "    \n",
        "    \n",
        "#     if A.shape[0]>0:\n",
        "#         print(A.head())\n",
        "        \n",
        "#         print(A.head())\n",
        "#         A.to_csv(dir+str(stockid)+'SRC_dt.csv', index=False)\n",
        "    return A\n",
        "\n",
        "def find_SRC_negative(dir,stockid,condition=True):\n",
        "#     now = datetime.now()\n",
        "#     Today = now.strftime(\"%Y-%m-%d\")\n",
        "#     print(Today)\n",
        "#     current_date = (now-timedelta(days=120)).isoformat()\n",
        "    price_db_name=dir+str(stockid)+\".sqlite\"\n",
        "    if os.path.isfile(price_db_name) is not True:\n",
        "        return\n",
        "    price_db_handler = sqlite3.connect(price_db_name)\n",
        "    df = pd.read_sql_query('SELECT OHLC.Date,OHLC.Close, SRC.M20 from SRC INNER JOIN OHLC ON SRC.Date = OHLC.Date order by SRC.Date ASC',price_db_handler)\n",
        "    df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    price_db_handler.close()\n",
        "    count_list=[]\n",
        "    date_st_list=[]\n",
        "    prc_st_list=[]\n",
        "    prc_st_20MA_list=[]\n",
        "    date_ed_list=[]\n",
        "    prc_ed_list=[]\n",
        "    prc_ed_20MA_list=[]\n",
        "    diff_20MA_list=[]\n",
        "    stockid_list=[]\n",
        "    one_M_price_list=[]\n",
        "#         \n",
        "    df['G_R_Cond']=df['M20']/abs(df['M20'])#定義正為1 負為-1\n",
        "    df['G_R_Cond'] = df['G_R_Cond'].fillna(0)\n",
        "    df['SRC M20 5dt']=(df['M20']-df['M20'].shift(5))/5\n",
        "#   抓取SRC 5dt連續性\n",
        "    df['SRC 5dt_G_R']=df['SRC M20 5dt']/abs(df['SRC M20 5dt'])\n",
        "    df['5dt_G_R_sum']=df['SRC 5dt_G_R'].rolling(window=10,min_periods=10).sum()\n",
        "#     df.loc[df['M20'] <0&, 'name_match'] = 'Match'\n",
        "    date_before = date.today() - timedelta(days=20)\n",
        "#     print(date_before)\n",
        "    df.loc[(df['M20']<0) & (df['5dt_G_R_sum']>8) & (df['Date'] > str(date_before))& (df['M20']>=-0.1),'RRR']=1\n",
        "    A=df.loc[df['RRR']==1]\n",
        "    if A.shape[0]>0:\n",
        "#         print(A.head())\n",
        "        A.to_csv(dir+str(stockid)+'SRC_dt.csv', index=False)\n",
        "    count_row = df.shape[0]\n",
        "    compare1=2\n",
        "    compare2=-1\n",
        "    if condition==False:\n",
        "        compare1=-2\n",
        "        compare2=1\n",
        "    a=1\n",
        "    while(a<count_row):\n",
        "#     for index in range(0,count_row-1):\n",
        "#         a=index+1\n",
        "        index=a-1\n",
        "        B=int(df.loc[index,['G_R_Cond']].values[0])\n",
        "        C=int(df.loc[a,['G_R_Cond']].values[0])\n",
        "#         print('loop pre',a)\n",
        "#        B-C=> 1-(-1)=2表示SRC開始由正轉負，反之 由負轉正\n",
        "        \n",
        "        re=B-C\n",
        "        if  re==compare1 :\n",
        "    #         print(index,a)\n",
        "            \n",
        "            count=1\n",
        "            while(1):\n",
        "                a=a+1\n",
        "                if a < count_row and int(df.loc[a,['G_R_Cond']].values[0])  == compare2:\n",
        "                    count=count+1\n",
        "                else:\n",
        "                    if a >= count_row:\n",
        "                        a=count_row-1\n",
        "#                     print(a)\n",
        "                    break\n",
        "            if count>20: # SRC<0 連續20次\n",
        "                \n",
        "                date_st=df.loc[index,['Date']].values[0]\n",
        "                prc_st_20MA=df.loc[index,['20 Day MA']].values[0]\n",
        "                prc_st=df.loc[index,['Close']].values[0]\n",
        "#                 date_ed=date_ed=df.loc[a,['Date']].values[0]\n",
        "                prc_ed_20MA=df.loc[a,['20 Day MA']].values[0]\n",
        "                prc_ed=df.loc[a,['Close']].values[0]\n",
        "                diff_20MA=(prc_ed_20MA-prc_st_20MA)/prc_ed_20MA\n",
        "                date_ed=df.loc[a,['Date']].values[0]\n",
        "                \n",
        "                \n",
        "                Next_M=a+30\n",
        "                if a+30>= count_row:# 取得{D+30  or 最新的}price\n",
        "                    Next_M=count_row-1\n",
        "#                 one_M_price=df.loc[Next_M,['20 Day MA']].values[0]\n",
        "                if diff_20MA < 0: # 20MA均線呈現下降\n",
        "                    count_list.append(count)\n",
        "                    date_st_list.append(date_st)\n",
        "                    prc_st_list.append(prc_st)\n",
        "                    prc_st_20MA_list.append(\"{:.2f}\".format(prc_st_20MA))\n",
        "                    \n",
        "                    date_ed_list.append(date_ed)\n",
        "                    prc_ed_list.append(prc_ed)\n",
        "                    prc_ed_20MA_list.append(\"{:.2f}\".format(prc_ed_20MA))\n",
        "                    \n",
        "                    diff_20MA_list.append(\"{:.4f}\".format(diff_20MA))\n",
        "                    stockid_list.append(str(stockid))\n",
        "                    \n",
        "                    one_M_price=df.loc[Next_M,['20 Day MA']].values[0]\n",
        "                    one_M_price_list.append(one_M_price)\n",
        "                    \n",
        "                    \n",
        "#                     A=df.loc[index:a,['Close diff 20 Day MA']]\n",
        "#                     print(A,len(A))\n",
        "#                     print(count,\",\"\n",
        "#                       ,date_st,\",\",\"{:.2f}\".format(prc_st_20MA)\n",
        "#                       ,\",\",date_ed,\",\",\"{:.2f}\".format(prc_ed_20MA)\n",
        "#                       ,\",\",\"{:.4f}\".format(diff_20MA)\n",
        "#                       ,\",\",\"{:.2f}\".format(one_M_price),\",\",str(stockid))\n",
        "                        \n",
        "#                   Using lists in dictionary to create dataframe\n",
        "\n",
        "        a=a+1\n",
        "#     df['Close diff 20 Day MA']=(df['20 Day MA']-df['Close'])/df['Close']\n",
        "#     df.to_csv('Close diff 20 Day MA.csv', index=False)\n",
        "    dicty = {'count_list':count_list\n",
        "             ,'date_st_list': date_st_list,'prc_st_list': prc_st_list,'prc_st_20MA_list': prc_st_20MA_list\n",
        "             ,'date_ed_list': date_ed_list,'prc_ed_list': prc_ed_list,'prc_ed_20MA_list': prc_ed_20MA_list\n",
        "             ,'diff_20MA_list': diff_20MA_list,'one_M_price_list':one_M_price_list,'stockid_list':stockid_list,} \n",
        "    rf = pd.DataFrame(dicty) \n",
        "    return rf\n",
        "\n",
        "\n",
        "\n",
        "def find_SRC_back_positive(df,str_index,boundary=90,continue_times=20,find_positive=True):\n",
        "    # str_index=307\n",
        "    end_index=str_index-boundary+2\n",
        "\n",
        "    if end_index <= 0:\n",
        "#         print(str_index)\n",
        "#         print(end_index)\n",
        "#         print(df.shape[0])\n",
        "        return None,None\n",
        "    compare1=-2\n",
        "    compare2=1\n",
        "    if find_positive is not True:\n",
        "        compare1=2\n",
        "        compare2=-1\n",
        "#第一層while是要找出斜率  開始由正轉負，反之 由負轉正\n",
        "    while(str_index > end_index):\n",
        "        str_index=str_index-1\n",
        "        index=str_index-1\n",
        "        B=int(df.loc[str_index,['G_R_Cond']].values[0])\n",
        "        C=int(df.loc[index,['G_R_Cond']].values[0])\n",
        "    # print('loop pre',str_index)\n",
        "    # B-C=> 1-(-1)=2表示SRC開始由正轉負，反之 由負轉正 修改\"find_positive\"\n",
        "        diff=B-C\n",
        "        if  diff==compare1 :\n",
        "    #         print(index,str_index)\n",
        "    #         print(df.loc[str_index,['Date']].values[0])\n",
        "            count=1\n",
        "#第二層while檢測SRC斜率的連續性，如果要容許不連續要再做修改\n",
        "            while(str_index >= end_index):\n",
        "                str_index=str_index-1\n",
        "                if str_index > end_index and int(df.loc[str_index,['G_R_Cond']].values[0])  == compare2:\n",
        "                    count=count+1\n",
        "                else:\n",
        "#                     if str_index >= end_index:\n",
        "    #                     str_index=count_row-1\n",
        "#                         print(str_index,count)\n",
        "    #                     print(count)\n",
        "                    break\n",
        "            if count > continue_times:\n",
        "#                 print(index)\n",
        "#                 print(df.loc[index,['Date']].values[0])\n",
        "                Date=df.loc[index,['Date']].values[0]\n",
        "#                 print(Date)\n",
        "                return Date,index\n",
        "    return None,None\n",
        "#                 print(df.loc[str_index+count,['Date']].values[0])\n",
        "    #         else:\n",
        "    #             print(count)\n",
        "\n",
        "\n",
        "# In[68]:\n",
        "def query_(dir,stockid,boundary,date):\n",
        "    price_db_name=dir+str(stockid)+\".sqlite\"\n",
        "    # if os.path.isfile(price_db_name) is not True:\n",
        "    #     return\n",
        "    price_db_handler = sqlite3.connect(price_db_name)\n",
        "    tat='SELECT * FROM(SELECT OHLC.Date,OHLC.Close,SRC.M20 from  SRC INNER JOIN OHLC ON SRC.Date = OHLC.Date order by SRC.Date DESC )WHERE Date <=\"'+ str(date) +'\"order by Date desc  LIMIT \"'+str(boundary)+'\"'\n",
        "    # df = pd.read_sql_query('SELECT OHLC.Date,OHLC.Close, SRC.M20 from SRC INNER JOIN OHLC ON SRC.Date = OHLC.Date order by SRC.Date ASC',price_db_handler)\n",
        "    # df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    df = pd.read_sql_query(tat,price_db_handler)\n",
        "    price_db_handler.close()\n",
        "    \n",
        "    df=df.iloc[::-1]\n",
        "    df.reset_index(drop=True,inplace=True)\n",
        "    df['G_R_Cond']=df['M20']/abs(df['M20'])#定義正為1 負為-1\n",
        "    df['G_R_Cond'] = df['G_R_Cond'].fillna(0)\n",
        "    # priec M20 slope \n",
        "    df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    df['20 Day MA']=df['20 Day MA'].shift(1)\n",
        "    df.loc[:,'20 Day MA_5dt']=((df['20 Day MA']-df['20 Day MA'].shift(5))/df['20 Day MA'].shift(5)).round(4)\n",
        "    return df\n",
        "# 分析SRC 於負的區間的時間與 股價變化\n",
        "# Step 1透過find_SRC_negative 先找出 SRC 斜率 上升 且即將由負轉正\n",
        "# Step 2 針對各別時間點，再往前搜尋最後一次SRC由正轉負的\n",
        "\n",
        "def find_SRC_negative_area(dir,stockid,boundary=600):\n",
        "    df=find_SRC_negative_v2(dir=dir,stockid=stockid,boundary=boundary)\n",
        "    # df\n",
        "#     df.loc[:,'indexCompare']=df.index.values\n",
        "\n",
        "#     df.loc[:,'indexCompare']=df['indexCompare']-df['indexCompare'].shift(1)\n",
        "\n",
        "#     drop_list=[]\n",
        "#     for i , row in  df.iterrows():\n",
        "#         if(pd.isnull(row['indexCompare'])):\n",
        "#             continue\n",
        "#        # 透過index - index shift 為一的特性，append連續資料，除了連續資料的第一個e.g. 5=鄰近的五天 \n",
        "#         if int(row['indexCompare']) <5:\n",
        "#             drop_list.append(i)\n",
        "\n",
        "#     # drop 連續的資料\n",
        "#     dfr=df.drop(drop_list)\n",
        "#     del dfr['indexCompare\n",
        "\n",
        "#     print(df)\n",
        "    dfr=continue_remove(df,5)\n",
        "#     print('-----')\n",
        "#     print(dfr)\n",
        "\n",
        "    # SRC 負值開始可回朔天數須大於90天，需要夠長的區間進行分析\n",
        "\n",
        "    dfr.loc[:,'indexCompare']=dfr.index.values\n",
        "\n",
        "\n",
        "     # print(df.tail())\n",
        "#     df.to_csv('stockid'+str(stockid)+'.csv', index=False)\n",
        "#     df[]\n",
        "    target=dfr[['indexCompare', 'Date']]\n",
        "#     print(target)\n",
        "    dfG = pd.DataFrame(columns=['str_date','str_index',\n",
        "                            'end_date','end_index','during'])\n",
        "    \n",
        "    boundary=90\n",
        "    \n",
        "    \n",
        "    for row in target.itertuples():\n",
        "        end_index=getattr(row, 'indexCompare')\n",
        "        dateA=getattr(row, 'Date')\n",
        "        df=query_(dir=dir,stockid=stockid,boundary=boundary,date=dateA)\n",
        "        \n",
        "        index_A=df.loc[df['Date']==dateA]\n",
        "        # print(index_A.index.values)\n",
        "        end_index=index_A.index.values[0]\n",
        "        Date,str_ind=find_SRC_back_positive(df=df,str_index=end_index,boundary=boundary)\n",
        "#         print(Date)\n",
        "#         分析區間內的股價變化\n",
        "        if Date is not None:       \n",
        "#             print(str_ind,getattr(row, 'Date'))\n",
        "#             print(str_ind,end_index)\n",
        "            dfG = dfG.append({'str_date': Date,'str_index':str_ind,'end_date':getattr(row, 'Date'),'end_index':end_index,'during':end_index-str_ind}, ignore_index=True)\n",
        "#     print(dfG)\n",
        "    return dfG,df\n",
        "    \n",
        "\n",
        "def continue_remove(df,diff=3):\n",
        "    df.loc[:,'indexCompare']=df.index.values\n",
        "\n",
        "    df.loc[:,'indexCompare']=df['indexCompare']-df['indexCompare'].shift(1)\n",
        "\n",
        "    drop_list=[]\n",
        "    for i , row in  df.iterrows():\n",
        "        if(pd.isnull(row['indexCompare'])):\n",
        "            continue\n",
        "       # 透過index - index shift 為一的特性，remove  相差小於diff的資料。除了連續資料的第一個 \n",
        "        if int(row['indexCompare']) <diff:\n",
        "            drop_list.append(i)\n",
        "\n",
        "    # drop 連續的資料\n",
        "    dfr=df.drop(drop_list)\n",
        "    del dfr['indexCompare']\n",
        "    return dfr\n",
        "\n",
        "\n",
        "\n",
        "def show_period_MA20_status(dfG,df):\n",
        "    for row in dfG.itertuples():\n",
        "        str_index=getattr(row, 'str_index')\n",
        "        end_index=getattr(row, 'end_index')\n",
        "    #         print(getattr(row, 'str_date'))\n",
        "        A=df.iloc[str_index:end_index]\n",
        "\n",
        "    #  找出斜率|x|<=0.002 的發生點\n",
        "    #         PR=A[A['20 Day MA_5dt']<=0.002 & A['20 Day MA_5dt']>=-0.002]\n",
        "        cond1=A['20 Day MA_5dt']<=0.002\n",
        "        cond2=A['20 Day MA_5dt']>=-0.002\n",
        "    #         PR=A[A['20 Day MA_5dt']<=0.002]\n",
        "\n",
        "        PR=A.loc[cond2 & cond1 ]\n",
        "        head=A.iloc[0:1]\n",
        "        tail=A.tail(1)\n",
        "    #     data = []\n",
        "    #     data.insert(0, head)\n",
        "    # 檢查是否已存在，插入頭尾兩筆資料\n",
        "        PR=pd.concat([head, PR], ignore_index=False)\n",
        "        PR=pd.concat([PR,tail], ignore_index=False)\n",
        "        # dropping duplicate values \n",
        "        PR.drop_duplicates(keep='first',inplace=True) \n",
        "        PR=continue_remove(PR)\n",
        "        print(PR)\n",
        "\n",
        "        # 依照區間進行分析曲線 升 降\n",
        "\n",
        "        arr=PR[:].index.values\n",
        "        # arr\n",
        "        for i in range(len(arr)-1):\n",
        "            print(arr[i],arr[i+1])\n",
        "            str_index=arr[i]\n",
        "            end_index=arr[i+1]\n",
        "            tmp=df.iloc[str_index:end_index+1]\n",
        "#             print(tmp)\n",
        "        #     統計 20 Day MA_5dt 正負的次數?\n",
        "            cond1=tmp['20 Day MA_5dt']>0.0\n",
        "            positive=tmp.loc[ cond1 ]\n",
        "\n",
        "#             print('正:',positive.shape[0])\n",
        "#             print('負:',tmp.shape[0]-positive.shape[0])    \n",
        "#         print('----------------------')\n",
        "# print(dfG)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def modification_date(filename):\n",
        "    t = os.path.getmtime(filename)\n",
        "    R=datetime.fromtimestamp(t)\n",
        "    return R.strftime(\"%Y-%m-%d\")    \n",
        "def local_file(last_folder,Nodir=True):\n",
        "    # 歷遍資料夾下的的檔案名稱，符合後紀錄於local_files\n",
        "    local_files=list()\n",
        "\n",
        "    for root, dirs, files in os.walk(last_folder, topdown=True):\n",
        "        for name in files:\n",
        "            modify_time=modification_date(last_folder+'/'+name)\n",
        "            name=name.replace(\"'\",\"\")\n",
        "            if 'sqlite' in name and len(name) == 11:\n",
        "                name=name.replace(\".sqlite\",\"\")\n",
        "                if Nodir is False:\n",
        "                    data= (last_folder+'/'+name,modify_time)\n",
        "                else:\n",
        "                    data= (name,modify_time)\n",
        "                local_files.append(data)\n",
        "#                 file_time.append(modify_time)\n",
        "    return local_files\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bollinger_bands(data,bis=2):\n",
        "#     data=copy.deepcopy(df)\n",
        "    data['std']=data['Close'].rolling(window=20,min_periods=20).std()\n",
        "    # data['std']=data['std'].shift(1)\n",
        "#     data['5 Day MA Vol']=data['Volume'].rolling(window=5,min_periods=5).mean()\n",
        "#     data['5 Day MA Vol']=data['5 Day MA Vol'].shift(1)\n",
        "#     temp=[]\n",
        "#     temp=data['Volume']/data['5 Day MA Vol']\n",
        "#     data['Vol > 5 Day MA Vol']=temp.where(temp>=3)\n",
        "#     data['5 Day MA Vol'].loc[0] = data['5 Day MA Vol'1].loc[1]\n",
        "#     data['5 Day MA Vol'].drop([len(data['5 Day MA Vol'])])\n",
        "\n",
        "    data['20 Day MA']=data['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    # data['20 Day MA']=data['20 Day MA'].shift(1)\n",
        "    data['Upper Band']=data['20 Day MA']+bis*data['std']\n",
        "    data['Lower Band']=data['20 Day MA']-bis*data['std']\n",
        "    #布林帶寬\n",
        "    data['bolling Bandwith']=(data['Upper Band']-data['Lower Band'])/data['20 Day MA']\n",
        "#     data['bolling Bandwith 10MA']=data['bolling Bandwith'].rolling(window=10,min_periods=10).mean()\n",
        "#     data['bolling Bandwith 5MA']=data['bolling Bandwith'].rolling(window=5,min_periods=5).mean()\n",
        "    #10 布林帶寬變化\n",
        "#     data['10 bolling Band std']=data['bolling Bandwith'].rolling(window=10,min_periods=10).std()\n",
        "    #保留小數點後第二位\n",
        "    data=data.round({'bolling Bandwith':2,'10 bolling Band std':2})\n",
        "    \n",
        "    #data[\"bolling Bandwith < 5%\"]=data['bolling Bandwith'].where(data['bolling Bandwith']<0.05)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "def forecast_Evaluate(dir,stockid,end_date,forecast_day=60):\n",
        "    # search stock for future x day find max/min price \n",
        "    price_db_name=dir+str(stockid)+\".sqlite\"\n",
        "    # if os.path.isfile(price_db_name) is not True:\n",
        "    #     return\n",
        "    price_db_handler = sqlite3.connect(price_db_name)\n",
        "    df = pd.read_sql_query('SELECT Date,Close from OHLC where Date >=\"'+str(end_date)+'\" order by Date ASC LIMIT \"'+str(forecast_day)+'\"',price_db_handler)\n",
        "    # df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    if df.shape[0]<60:\n",
        "        forecast_day=df.shape[0]\n",
        "    # end_date\n",
        "    # retrive max/min price  close data  forecast_day\n",
        "    # df\n",
        "    column = df['Close']\n",
        "    max_index = column.idxmax()\n",
        "\n",
        "    min_index=column.idxmin()\n",
        "    # compare end date close price with max min\n",
        "    Hdiff=(column[max_index]-column[0])/column[0]\n",
        "    Ldiff=(column[min_index]-column[0])/column[0]\n",
        "    result=False\n",
        "    G=0.11\n",
        "    H=0.2\n",
        "    # 跌幅<G 漲幅>H\n",
        "    diff=Ldiff\n",
        "    if abs(Ldiff)<G and Hdiff>H:\n",
        "#     if Hdiff>H:\n",
        "        result=df.at[max_index,'Date']\n",
        "        diff=Hdiff\n",
        "    else:\n",
        "        result=df.at[min_index,'Date']\n",
        "    return result,diff,column[0]\n",
        "\n",
        "def break_bolling_low(dir,socketid,str_date,end_date):\n",
        "#     forecast_day=120\n",
        "#     socketid=2301\n",
        "#     str_date='2020-01-10'\n",
        "#     end_date='2020-04-01'\n",
        "    # search stock for future x day find max/min price \n",
        "    price_db_name=dir+str(socketid)+\".sqlite\"\n",
        "    # if os.path.isfile(price_db_name) is not True:\n",
        "    #     return\n",
        "    price_db_handler = sqlite3.connect(price_db_name)\n",
        "    dfb = pd.read_sql_query('SELECT Date,Close from OHLC where Date <\"'+str(str_date)+'\" order by Date DESC LIMIT 19',price_db_handler)\n",
        "    dfb.sort_values(by=['Date'], inplace=True)\n",
        "    df1 = pd.read_sql_query('SELECT Date,Close from OHLC where  Date<=\"'+ str(end_date) +'\"AND Date >=\"'+str(str_date)+'\" order by Date ASC',price_db_handler)\n",
        "    price_db_handler.close()\n",
        "    \n",
        "    df=pd.concat([dfb, df1])\n",
        "    \n",
        "    # df['20 Day MA']=df['Close'].rolling(window=20,min_periods=20).mean()\n",
        "    bollinger_bands(df,bis=2)\n",
        "#     print(df)\n",
        "#     df.to_csv('out.csv', index=False) \n",
        "    # df.drop(['B', 'C'], axis=1)\n",
        "    # df['']=\n",
        "    F=df['bolling Bandwith'].tail(1).values[0]\n",
        "    df.loc[df['Lower Band'] > df['Close'] , 'SING'] = 1 \n",
        "    df=df.iloc[19:]\n",
        "    df.reset_index(drop=True,inplace=True)\n",
        "    # price_db_handler.close()\n",
        "    if df.shape[0]<60:\n",
        "        forecast_day=df.shape[0]\n",
        "    # end_date\n",
        "    # retrive max/min price  close data  forecast_day\n",
        "    # df\n",
        "#     column = df['Close']\n",
        "#     max_index = column.idxmax()\n",
        "#     min_index=column.idxmin()\n",
        "#     # compare end date close price with max min\n",
        "#     Hdiff=(column[max_index]-column[0])/column[0]\n",
        "#     Ldiff=(column[min_index]-column[0])/column[0]\n",
        "#     result=False\n",
        "#     G=0.11\n",
        "#     H=0.2\n",
        "#     # 跌幅<G 漲幅>H\n",
        "#     if abs(Ldiff)<G and Hdiff>H:\n",
        "#         result=df.at[max_index,'Date']\n",
        "#     print(socketid)\n",
        "    #SING =1 Close price < Bolling Lower Band \n",
        "    condA=df['SING']==1\n",
        "    # df\n",
        "    E=df.loc[condA]\n",
        "#     跌破布林通道底部占比\n",
        "    P=0\n",
        "    M20_direction=0\n",
        "    if E.shape[0]>0:\n",
        "        P=E.shape[0]/df.shape[0]\n",
        "        A=E.at[E.head(1).index[0],'20 Day MA']\n",
        "        B=E.at[E.tail(1).index[0],'20 Day MA']\n",
        "        M20_direction = 1 if A>B else -1\n",
        "    return P,E.shape[0],M20_direction,F\n",
        "\n",
        "\n",
        "def SRC_notify(oldfilename,df):\n",
        "    new_df=df.loc[: ,['socketid','end_date']]\n",
        "\n",
        "    # 有資料才比較\n",
        "    new_df_A=new_df\n",
        "    if new_df.shape[0] > 0 :\n",
        "        # check if data exist\n",
        "        if os.path.isfile(oldfilename) :\n",
        "            old_df=pd.read_csv(oldfilename)\n",
        "            counter=old_df.shape[0] \n",
        "            for row in old_df.itertuples():\n",
        "                end_date=getattr(row, 'end_date')\n",
        "                socketid=getattr(row, 'socketid')\n",
        "                \n",
        "\n",
        "                condition = new_df_A['socketid'] == str(socketid)\n",
        "                Q=new_df_A.loc[condition]\n",
        "\n",
        "                index_A=Q.loc[Q['end_date']==end_date]\n",
        "                if index_A.shape[0]==1:\n",
        "                    new_df_A=new_df_A.drop(index_A.index.tolist())\n",
        "                    counter=counter-1 \n",
        "#            當counter=0 則表示old_df行數全比較完畢        \n",
        "            if len(new_df_A) == 0 and counter== 0:\n",
        "                print('the same')\n",
        "                return False\n",
        "        print('save file')\n",
        "        df.to_csv(oldfilename, encoding='utf-8',index=False)\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_SRC_by_condition(dir):\n",
        "    #  排序dir下的檔案\n",
        "    #print(\"F\")\n",
        "    A=local_file(dir)\n",
        "    file_df = pd.DataFrame(A, columns=['name','date'])\n",
        "    file_df.sort_values(by=\"name\",ascending=True,inplace=True)\n",
        "    stockid=2105\n",
        "\n",
        "\n",
        "    # data = pd.read_csv(dir+\"B.csv\", delimiter=',')\n",
        "    df1 = pd.DataFrame(columns=['count_list'\n",
        "                                ,'date_st_list','prc_st_list','prc_st_20MA_list'\n",
        "                                ,'date_ed_list','prc_ed_list','prc_ed_20MA_list'\n",
        "                                ,'diff_20MA_list','one_M_price_list','stockid_list'])\n",
        "\n",
        "    # pbar = ProgressBar()\n",
        "\n",
        "    Evaluate = pd.DataFrame(columns=['socketid','str_date','str_index',\n",
        "                                'end_date','end_index','during','forecast_Evaluate','end_close','price_diff','bolling Bandwith','Percentage_of_touch_bolling_bottom','times','M20_direction'])\n",
        "\n",
        "    # loop 所有檔案\n",
        "    for row in  file_df.itertuples():\n",
        "\n",
        "        stockid=getattr(row, 'name')\n",
        "        #print(stockid)\n",
        "        try:\n",
        "\n",
        "            dfG,df=find_SRC_negative_area(dir,stockid,boundary=100)\n",
        "        #     if dfG.shape[0]>0:\n",
        "        #         break\n",
        "        # 如果有資料則會彙整\n",
        "            for row in dfG.itertuples():\n",
        "                Evaluate = Evaluate.append({'socketid':stockid,'str_date': getattr(row, 'str_date'),'str_index':getattr(row, 'str_index')\n",
        "                                        ,'end_date':getattr(row, 'end_date'),'end_index':getattr(row, 'end_index')\n",
        "                                        ,'during':getattr(row, 'during')}, ignore_index=True)\n",
        "        #         dfG.to_csv(dir+str(stockid)+'SRC_dt.csv', index=False)\n",
        "        #     dfx=find_SRC_negative(dir=dir,stockid=stockid,condition=True)\n",
        "        #         pbar.update(5)\n",
        "        #     df1=pd.concat([df1, dfx])\n",
        "        except Exception as E:\n",
        "            print('Error :', E)\n",
        "            print(row)\n",
        "    print(Evaluate)\n",
        "\n",
        "    for row in Evaluate.itertuples():\n",
        "    #     print(row.Index)\n",
        "        end_date=getattr(row, 'end_date')\n",
        "        str_date=getattr(row, 'str_date')\n",
        "        socketid=getattr(row, 'socketid')\n",
        "        # \n",
        "        A,price_diff,end_close=forecast_Evaluate(dir,socketid,end_date)\n",
        "        P,E,G,J=break_bolling_low(dir,socketid,str_date,end_date)\n",
        "        Evaluate.at[row.Index,'forecast_Evaluate']=A\n",
        "        Evaluate.at[row.Index,'price_diff']=price_diff\n",
        "        Evaluate.at[row.Index,'bolling Bandwith']=J\n",
        "        Evaluate.at[row.Index,'end_close']=end_close\n",
        "        Evaluate.at[row.Index,'Percentage_of_touch_bolling_bottom']=P\n",
        "        Evaluate.at[row.Index,'times']=E\n",
        "        Evaluate.at[row.Index,'M20_direction']=G\n",
        "\n",
        "\n",
        "    cond2=Evaluate['times']>=0\n",
        "    # now = datetime.now()\n",
        "    now =date.today() - timedelta(days=60)\n",
        "    Today = now.strftime(\"%Y-%m-%d\")\n",
        "    print(Today)\n",
        "    cond3=Evaluate['end_date']>Today\n",
        "    cond1=Evaluate['bolling Bandwith']<2\n",
        "    cond4=Evaluate['end_close'] > 30\n",
        "    PR=Evaluate.loc[cond2 & cond1&cond4]\n",
        "    # print(PR.shape[0]/Evaluate.shape[0])\n",
        "    pd.set_option('display.max_rows', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', None)\n",
        "    # pd.set_option('display.max_colwidth', None)\n",
        "    # pd.set_option('display.max_colwidth', None)\n",
        "    # G=PR[PR['price_diff']>0.2]\n",
        "    # print(G.shape[0]/PR.shape[0])\n",
        "    PR.sort_values(by=['end_date'],inplace=True)\n",
        "    return PR.loc[: ,['socketid','end_date','end_close']]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# In[93]:\n",
        "def financing_target(stockid,ratio=0.06):\n",
        "  # stockid='2344'\n",
        "\n",
        "  _sql='select financing.date,financing.fin_cost,financing.fin_maintenance_rate,OHLC.Close from financing join OHLC on OHLC.date=financing.date '\n",
        "  # _sql='select * from OHLC'\n",
        "  G=readfromsql_v2(dir,str(stockid),sql=_sql)\n",
        "  if G is None:\n",
        "    return None\n",
        "  #F_10 days moveing average\n",
        "  G['F_10']=G['fin_maintenance_rate'].rolling(window=10,min_periods=10).mean()\n",
        "  #\n",
        "  G['F_cost_10']=G['fin_cost'].rolling(window=10,min_periods=10).mean()\n",
        "  G['F_10_diff']=(G['F_10']-G['fin_maintenance_rate'])/G['fin_maintenance_rate']\n",
        "  # today=\n",
        "  G.loc[G['F_10_diff']>ratio, 'SING'] = 1 \n",
        "  target=G[G['SING']==1]\n",
        "\n",
        "  # target['index1'] = target.index\n",
        "  target = target.reset_index(level=0)\n",
        "  target['index_shift']=target['index'].shift(1)\n",
        "  target['index_diff']=target['index']-target['index_shift']\n",
        "  target['index_diff']=target['index_diff'].shift(-1)\n",
        "  # 計算是否連續發生(透過dataframe index)\n",
        "  # target['index_diff'] = target['index_diff'].fillna(0)\n",
        "  condA=target['index_diff'] == 0 #\n",
        "  condB=target['index_diff'] > 1\n",
        "\n",
        "  # 將最後一筆資料手動手入，並移除重複index，並確保區間forloop檢測點完整\n",
        "  pagination=target[condB|condA]\n",
        "\n",
        "  # pagination\n",
        "  if pagination.shape[0] < 1:\n",
        "    return\n",
        "\n",
        "  pagination = pagination.append(target.head(1),ignore_index=True)\n",
        "  pagination = pagination.append(target.tail(1),ignore_index=True)\n",
        "  pagination.drop_duplicates(subset=\"index\",keep='first', inplace=True)\n",
        "  pagination.sort_values(by=['index'], inplace=True,ignore_index=True)\n",
        "  # print(pagination)\n",
        "  # 去除重複值，檢測點數量僅有一筆，則跳過\n",
        "  if pagination.shape[0] == 1:\n",
        "    return\n",
        "  # range=pagination.copy()\n",
        "  \n",
        "  for i in range(len(pagination['index'])-1):\n",
        "    # print(pagination['index'].at[i])\n",
        "    condA=target['index']<int(pagination['index'].at[i+1])\n",
        "    condB=target['index']>=int(pagination['index'].at[i])\n",
        "    rangae=target[condA & condB]\n",
        "    # print(rangae.tail(1)['Date'])\n",
        "    # df.at[row_label, column_name] = 78\n",
        "    # print(int(pagination['index'].at[i+1]))\n",
        "    target.loc[target['index'] == int(pagination['index'].at[i+1]), 'm_time'] = rangae.shape[0]\n",
        "\n",
        "  # pagination[pagination['index']==]\n",
        "  \n",
        "  # target\n",
        "  if target[['index_diff']].iloc[1].values != 1.0:\n",
        "    target.loc[0, 'm_time']=1\n",
        "    # target[['m_time']].iloc[0]=1\n",
        "    # print(target[['index_diff']].iloc[1])\n",
        "  target=target[target['m_time']>0]\n",
        "  return target\n",
        "  # type(pagination['index'])\n",
        "def filter_financing(duration=10,ratio=0.06):\n",
        "  today = date.today()\n",
        "  # print(\"Today's date:\", str(today))\n",
        "  frome_date = today-timedelta(days=duration)\n",
        "  # print('Date String', today.strftime('%Y-%m-%d'))\n",
        "  today.strftime('%Y-%m-%d')\n",
        "  frome_date.strftime('%Y-%m-%d')\n",
        "  t = pd.DataFrame()\n",
        "  for stock_id in A:\n",
        "    # print(stock_id[0])\n",
        "    a=financing_target(str(stock_id[0]),ratio)\n",
        "    if a is None:\n",
        "      continue\n",
        "    a.drop(columns=['index_shift', 'SING','index','F_10','F_cost_10','F_10_diff','index_diff'],inplace=True)\n",
        "    condA=a['Date'] >= frome_date.strftime('%Y-%m-%d')\n",
        "    condB=a['Date'] <= today.strftime('%Y-%m-%d')\n",
        "    result=a[condA & condB]\n",
        "    result=result.copy()\n",
        "    result['stockid']=str(stock_id[0])\n",
        "    # print(result)\n",
        "    t=t.append(result, ignore_index=True)\n",
        "  # result\n",
        "  # t.sort_values(by=['Date'],inplace=True)\n",
        "  t.sort_values(by=['fin_maintenance_rate'],inplace=True)\n",
        "  return t\n",
        "\n",
        "def readfromsql_v2(dir,stockid,dateformate=False,sql=None):\n",
        "\n",
        "    price_db_name=dir+str(stockid)+\".sqlite\"\n",
        "    if os.path.isfile(price_db_name) is not True:\n",
        "        return\n",
        "    db_handler = sqlite3.connect(price_db_name)\n",
        "    cursor = db_handler.cursor()\n",
        "    cursor.execute('SELECT name FROM sqlite_master WHERE type =\"table\" And name = \"financing\"')\n",
        "    re = cursor.fetchall()\n",
        "    if len(re)<1:\n",
        "      return None\n",
        "    df_mysql = pd.read_sql_query(sql, db_handler)\n",
        "\n",
        "    db_handler.close()\n",
        "    return df_mysql\n",
        "\n",
        "dir='./small_test/'\n",
        "def main():\n",
        "    oldfilename='SRCresult.csv'\n",
        "    A=find_SRC_by_condition(dir=dir)\n",
        "    B=SRC_notify(oldfilename=oldfilename,df=A)\n",
        "#    C=SRC_notify(oldfilename=A,df=oldfilename)\n",
        "    print(A)\n",
        "    filter_financing()\n",
        "# In[94]:\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}